<!DOCTYPE HTML>
<!--
	Hielo by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>Ian Sibley</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
	</head>
	<body class="subpage">

		<!-- Header -->
			<header id="header">
				<div class="logo"> <a href="mailto:isibley@purdue.edu?subject=[ECE477]">Ian Sibley</a> </div>
				<a href="#menu">Menu</a>
			</header>

			<!-- Nav -->
				<nav id="menu">
					<ul class="links">
						<li><a href="../../index.html">Home</a></li>
						<li><a href="../../index.html#one">Team</a></li>
						<li><a href="../../documents/documents.html">Documents</a></li>
						<li><a href="https://github.com">Source</a></li>
						<li><a href="../../media/media.html">Media</a></li>
						<li><a href="../contacts.html">Contacts</a></li>
						<li><a href="https://engineering.purdue.edu/ece477/">ECE477</a></li>
					</ul>
				</nav>

		<!-- One -->
			<section id="One" class="wrapper style3">
				<div class="inner">
					<header class="align-center">
						<p style="font-size: 20px">Software Engineer</p>
						<h2 style="font-size: 50px">Progress Report</h2>
					</header>
				</div>
			</section>

		<!-- Two -->
			<section id="two" class="wrapper style2">
				<div class="inner">
					<div class="box">
						<div class="content">
							<header class="align-left">
								<h2><b>Week 1:</b></h2>
								<h1><b>Date:</b> January 11, 2019 </h1>
								<h1><b>Total hours:</b> 8.5 </h2>
								<h1><b>Description of Design Effors: </b></h1>
							</header>
							<p> Contributed to the finishing of the Final Proposal, and aided in the initial orientation to lab materials and account resources. PSSC's were my domain, and Yash aided with the pursuing of Todd for advice on edits, and we decided to take his advice and comments.
								There were thoughts that we may use a Bluetooth chip to connect with the Raspberry Pi so that the casing for the door mount could be smaller and more sleek.</p>
							<p> I was in charge of configuring the web page, I spent an evening ironing it out and fixing reference errors that were built in, only allowing it to access template files and images. Our files and images are in our group 2 folders, not the template folders, so there were obvious reasons why that was undesireable.
								We should be straightened out now, the eventual resolution is an easy fix if any remain. </p>
						</div>

						<div class="content">
							<header class="align-left">
								<span class="image right"><img src="../../media/images/pi_image.jpg" alt="blurry pi image"/><h1> Figure 2.1: Test Picture Taken with Pi Camera</h1></span>
								<h2><b>Week 2: </b></h2>
								<h1><b>Date:</b> January 18, 2019 </h1>
								<h1><b>Total hours:</b> 20 </h2>
								<h1><b>Description of Design Effors: </b></h1>
							</header>
							<p> In addition to contributing to the Assignment 2 document content and converting citations to IEEE format, efforts were made to acquire relevant materials available in lab to avoid purchasing every item. </p>
							<p> Most elements of our project were available in lab, fortunately. Some work was done to try and acquire picture and video frame capture from the Raspberry Pi and the camera, and video and images were pulled successfully. Frame capture will be done in the near future. </p>
							<p> As you can see, the image is also blurry, and this may be a concern for the facial recognition algorithm. Investigation in a USB camera alternative instead may be desireable. </p>
						</div>

						<div class="content">
							<header class="align-left">
								<h2><b>Week 3: </b></h2>
								<h1><b>Date:</b> January 25, 2019 </h1>
								<h1><b>Total hours:</b> 18 </h2>
								<h1><b>Description of Design Effors: </b></h1>
							</header>
							<p> We took a closer look at the software FaceNet and its documentation to complete the Software Overview. Inspection shows little documentation on how to use the network from within an application, however, besides activating it in a terminal setting and then presumably parsing its output text. </p>

								<span class="image left"><img src="../../media/images/pi_remote_accessible.png" alt="setup pi for remote access"/><h1> Figure 3.1: Setup for Remote Access in Lab</h1></span>
								<p>To this end, face_recognition is a library that prides itself in its ease of use and accuracy, though its install process may also potentially be touchy as well. Once installed, it is directly documented to show how images can be classified against a pretrained network, also for a 128 feature vector like FaceNet. Less reference is made for how this architecture is built or what it is based on, but we have the full potential to make the actual algorithm process a modular item, so that we can design with whichever module appears easiest in initial stages, and swap for the other if desired, treating it as a black box that takes in cropped face images and returns the feature vector. </p>
							<p> It has also been brought to our attention that a PyPi module <a style="color: blue" href="https://github.com/ishwarsawale/facenet_recognition">facenet_recognition</a> has been made for FaceNet with the intent for user convenience like with face_recognition, though it seems to still rely largely from physical files and folders. This isn't altogether a disadvantage, and may prove to be a good compromise. </p>
							<p> Finally, it was discovered that the Raspberry Pi was able to be seen and connected outside of lab, as long as access to either Purdue WiFi was available or a Purdue VPN was used at home. So, this has been taken to great effect for lengthy installs of OpenCV, Tensorflow, and currently DLIB, though there have been some minor issues with DLIB. We will be trying again over the coming weekend, and but otherwise may be limited to doing the face cropping on the server side of things. Most Pi progress has been investment in the lengthier installs this week, usually when they don't work without extra care. </p>

								<span class="image right"><img src="../../media/images/installs_finally_worked.png" alt="installs finally worked"/><h1> Figure 3.2: Installs Finally Worked</h1></span>
								<p>We also discussed ( I believe with Professor Thottethodi and (an)other TA(s) ) about changing our PSSC's from pointing at I2C to UART for communication with the Bluetooth module, as the bluetooth module found in the lab to use did not have I2C on its board. </p>
							<hr/>
							<p> Update: all libraries installed to the Pi, once the camera is calebrated we'll be able to start initial software design tests. </p>
						</div>

						<div class="content">
							<header class="align-left">
								<h2><b>Week 4: </b></h2>
								<h1><b>Date:</b> January 31, 2019 </h1>
								<h1><b>Total hours:</b> 12 </h2>
								<h1><b>Description of Design Effors: </b></h1>
							</header>
							<p>
								The cold kept us from having lab, but I was able to put a good amount of work in all the same to streaming the taken pictures from the Pi to a WiFi/Ethernet connected device.
							</p>
							<p>
								<p style="margin: 0px">Frames from Pi Camera capturing</p>
								<span class="image left four-show">
									<img class="four-single-image" src="../../media/images/piFrameCaptures/frame6.jpg" alt="Pi Frame Capture"/>
									<img class="four-single-image" src="../../media/images/piFrameCaptures/frame2.jpg" alt="Pi Frame Capture"/>
									<img class="four-single-image" src="../../media/images/piFrameCaptures/frame5.jpg" alt="Pi Frame Capture"/>
									<img class="four-single-image" src="../../media/images/piFrameCaptures/frame8.jpg" alt="Pi Frame Capture"/>
									<h1> Figure 4.1: Four Frame Captures from the Pi Camera</h1>
								</span>
								The big challenge from here was working with the code to get something that's able to be pulled into an application program, rather than a one-off run file. The examples found online, including one that involved threading and was very efficient, were messy, used global variables everywhere, and was resistive to being turned into classes and functions. And when they were, the extra structure interfered with the threading enough that the best I could find was 2 frames per second, slower than what we decided was useful.
								So I switched back to a synchronous/non-threaded approach, and was able to easily get a little over our targeted 4fps even from an of campus connection. There's a small amount of work that'll be done to pull it into an application (making and sustaining connections and camera priming, to reduce wait times), but that's only a short way off now.
							</p>
							<p> The frames are sideways cause that was the easiest way to prop the camera up for now, we'll have it mounted in the end product correctly. </p>
						</div>

						<div class="content">
							<header class="align-left">
								<h2><b>Week 5: </b></h2>
								<h1><b>Date:</b> February 8th, 2019 </h1>
								<h1><b>Total hours:</b> 14 </h2>
								<h1><b>Description of Design Effors: </b></h1>
							</header>
							<p>
								The cold kept us from having lab, but I was able to put a good amount of work in all the same to streaming the taken pictures from the Pi to a WiFi/Ethernet connected device.
							</p>
							<p style="margin: 0px">Successful image transmisions and result responses to and from the Pi</p>
							<span class="image fit">
								<img class="" src="../../media/images/piToCompToPiSuccess.png" alt="Pi Frame Capture"/>
								<h1> Figure 5.1: Pi Frame Capture</h1>
							</span>
							<p>
								Did a lot of work this week trying to get the Pi to organize the streaming into an application-style file. Everything is centered around one application.py file, and it checks to make sure Python 3+ is used for uniformity.
								This runs both the Pi and the Computer/Server code, after checking the operating system, and the Computer was turned into the server in respect to the Socket connection again, since this makes much more sense in a functional flow design.
							</p>
							<p>
								FaceNet was effective, but turned out to be very terminal output and file reading/writing based, which slows down the computer processing segment significantly. Using the face_recognition library was a quick switch, and significantly faster.
								Pre-processing of the known images can happen before a user even initiates the image transfer, saving a large amount of time generating the feature vectors, saving pre-known feature vectors to files to be read and loaded in instead. All that's left is taking the images of the current user, finding the feature vectors from them, and comparing, and face_recognition provides an interface to do that process efficiently as well.
								All together, the switch was easy, and the DLIB-based face_recognition library was both quicker and designed for application use much better than the facenet_recognition library. Accuracy has been spot on so far as well, even with small known user sets: only once or twice have I been slightly mistaken for Evan in the output results, and that was a magnitude or two of difference in the confidence value for identifying me, I was very obviously still the person found in the picture.
							</p>
							<p>
								From there, a connection was just needed for sending the results down to the Pi. That took a bit of time, as the Socket library isn't terribly documented on the background functionality and took a good bit of trial and error on my part, but eventually a JSON packet of name: confidence values was able to be sent down to the Pi cleanly, as the picture shows.
								From there, we'll need to get Bluetooth working to work on the next part of the application. The Micro will be the major step for that, as we'll need a way to test that we've got a stable connection, and to send/receive input from the connected device. We'll likely invest time in finding and connecting to a phone app that'll let us do similar work with the Pi and the microcontroller.
							</p>
						</div>
					</div>
				</div>
			</section>


		<!-- Footer -->
			<footer id="footer">
				<div class="container">
					<ul class="icons">
						<li><a href="https://github.com" class="icon fa-github"><span class="label">Github</span></a></li>
						<li><a href="mailto:mill1576@purdue.edu,isibley@purdue.edu,ynain@purdue.edu,vzhuleva@purdue.edu?subject=[ECE477]" class="icon fa-envelope-o"><span class="label">Email Us</span></a></li>
					</ul>
				</div>
				<div class="copyright">
					&copy; Hielo by TEMPLATED. All rights reserved.
				</div>
			</footer>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/jquery.scrollex.min.js"></script>
			<script src="../../assets/js/skel.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<script src="../../assets/js/main.js"></script>

	</body>
</html>
